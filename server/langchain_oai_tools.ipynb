{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.chat import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "import query_tool\n",
    "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
    "from langchain.memory import ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "   query_tool.reference_code_search\n",
    "  ]\n",
    "\n",
    "message_history = RedisChatMessageHistory(\n",
    "    url=\"redis://localhost:6379/0\", ttl=600, session_id=\"my-session\"\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", chat_memory=message_history, return_messages=True, human_prefix=\"human\", ai_prefix=\"ai\", input_key=\"input\", output_key=\"output\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"You are an AWS solutions architect. Your job is to help customers build and deploy secure applications on AWS. Follow architecture best practices and find out approriate requirements before suggesting a solution. Only call tools once necessary for generating a final terraform file.\"),\n",
    "  (\"human\", \"My current terraform file:\\n{tf_file}\"),\n",
    "  MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "  (\"human\", \"{input}\"),\n",
    "  \"{agent_scratchpad}\"\n",
    "])\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=.5)\n",
    "# Construct the OpenAI Tools agent\n",
    "agent = create_openai_tools_agent(llm, tools, prompt) # type: ignore # wrong type for query_tool import\n",
    "\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory, max_iterations=2, early_stopping_method=\"generate\", return_intermediate_steps=True) # type: ignore # wrong type for query_tool import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_executor.run({\n",
    "#   \"input\": \"Hi\",\n",
    "#     \"tf_file\": \"```terraform resource \\\"aws_instance\\\" \\\"example\\\" { ami = \\\"${data.aws_ami.ubuntu.id}\\\" instance_type = \\\"t2.micro\\\" }```\",\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe instance type used in the provided Terraform file is \"t2.micro\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Which instance type is my provided tf file currently using? dont use any tools.',\n",
       " 'tf_file': '```terraform resource \"aws_instance\" \"example\" { ami = \"${data.aws_ami.ubuntu.id}\" instance_type = \"t2.micro\" }```',\n",
       " 'chat_history': [],\n",
       " 'output': 'The instance type used in the provided Terraform file is \"t2.micro\".',\n",
       " 'intermediate_steps': []}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "  \"input\": \"Which instance type is my provided tf file currently using? dont use any tools.\",\n",
    "  \"tf_file\": \"```terraform resource \\\"aws_instance\\\" \\\"example\\\" { ami = \\\"${data.aws_ami.ubuntu.id}\\\" instance_type = \\\"t2.micro\\\" }```\",\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infragen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
