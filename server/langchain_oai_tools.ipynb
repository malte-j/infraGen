{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.chat import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "import submit_code_tool\n",
    "import query_tool\n",
    "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
    "from langchain.memory import ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "   query_tool.reference_code_search,\n",
    "   submit_code_tool.create_submission_tool(\"my_session\")\n",
    "  ]\n",
    "\n",
    "message_history = RedisChatMessageHistory(\n",
    "    url=\"redis://localhost:6379/0\", session_id=\"my-session\"\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", chat_memory=message_history, return_messages=True, human_prefix=\"human\", ai_prefix=\"ai\", input_key=\"input\", output_key=\"output\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"\"\"\n",
    "   You are an AWS solutions architect. Your job is to help customers build and deploy secure applications on AWS. \n",
    "   At first, you need to understand the customer's requirements. Make sure all the requirements are clear and precise before working on the terraform code.\n",
    "\n",
    "   When you have enough information, you can work on the terraform code. If the user has provided a terraform file, use this as a starting point and try to modify it to meet the requirements. Follow the architecture best practices (like not storing secrets in the code) by using the reference_code_search. Do not paste the code into the chat. Instead, use the create_submission_tool to submit the code to the user.\n",
    "\n",
    "   If anything is unclear, ask the user for more information.\n",
    "   \n",
    "   Tools:\n",
    "   - reference_code_search: Use this tool to get terraform best practice reference code from the AWS samples repository. If no results are found, stop using this function.\n",
    "   - create_submission_tool: Use this tool to submit the terraform file to the user.\n",
    "   \"\"\"),\n",
    "  (\"human\", \"My current terraform file:\\n{tf_file}\"),\n",
    "  MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "  (\"human\", \"{input}\"),\n",
    "  \"{agent_scratchpad}\"\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-1106-preview\", temperature=.5)\n",
    "\n",
    "# Construct the OpenAI Tools agent\n",
    "agent = create_openai_tools_agent(llm, tools, prompt) # type: ignore # wrong type for query_tool import\n",
    "\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory, max_iterations=8, early_stopping_method=\"generate\", return_intermediate_steps=True) # type: ignore # wrong type for query_tool import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "r = redis.Redis(host=\"localhost\", port=6379, decode_responses=True)\n",
    "messages = r.lrange(\"message_store:my-session\", 0, -1)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\n",
    "  \"input\": \"I need a manged postgres database without specific requirements. No high availability, but at least daily backups.\",\n",
    "  \"tf_file\": \"```terraform resource \\\"aws_instance\\\" \\\"example\\\" { ami = \\\"${data.aws_ami.ubuntu.id}\\\" instance_type = \\\"t3.micro\\\" }```\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\n",
    "  \"input\": \"I need a webserver.\",\n",
    "  \"tf_file\": \"\",\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infragen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
